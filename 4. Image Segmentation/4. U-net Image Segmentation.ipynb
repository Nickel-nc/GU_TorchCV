{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation for [set-lipstick-original dataset](https://www.kaggle.com/olekslu/makeup-lips-segmentation-28k-samples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score as jsc\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import pyplot as plt \n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "# !pip install segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image00000001.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>661</td>\n",
       "      <td>394</td>\n",
       "      <td>776</td>\n",
       "      <td>444</td>\n",
       "      <td>mask00000001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image00000002.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>557</td>\n",
       "      <td>336</td>\n",
       "      <td>682</td>\n",
       "      <td>392</td>\n",
       "      <td>mask00000002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image00000003.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>553</td>\n",
       "      <td>369</td>\n",
       "      <td>684</td>\n",
       "      <td>427</td>\n",
       "      <td>mask00000003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image00000004.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>555</td>\n",
       "      <td>351</td>\n",
       "      <td>681</td>\n",
       "      <td>408</td>\n",
       "      <td>mask00000004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image00000005.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>555</td>\n",
       "      <td>351</td>\n",
       "      <td>680</td>\n",
       "      <td>407</td>\n",
       "      <td>mask00000005.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28589</th>\n",
       "      <td>image00028590.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>657</td>\n",
       "      <td>347</td>\n",
       "      <td>817</td>\n",
       "      <td>450</td>\n",
       "      <td>mask00028590.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28590</th>\n",
       "      <td>image00028591.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>713</td>\n",
       "      <td>325</td>\n",
       "      <td>884</td>\n",
       "      <td>388</td>\n",
       "      <td>mask00028591.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28591</th>\n",
       "      <td>image00028592.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>659</td>\n",
       "      <td>401</td>\n",
       "      <td>808</td>\n",
       "      <td>488</td>\n",
       "      <td>mask00028592.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28592</th>\n",
       "      <td>image00028593.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>689</td>\n",
       "      <td>334</td>\n",
       "      <td>839</td>\n",
       "      <td>431</td>\n",
       "      <td>mask00028593.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28593</th>\n",
       "      <td>image00028594.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>657</td>\n",
       "      <td>381</td>\n",
       "      <td>817</td>\n",
       "      <td>476</td>\n",
       "      <td>mask00028594.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28594 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename  width  height class  xmin  ymin  xmax  ymax  \\\n",
       "0      image00000001.jpg   1280     720  Lips   661   394   776   444   \n",
       "1      image00000002.jpg   1280     720  Lips   557   336   682   392   \n",
       "2      image00000003.jpg   1280     720  Lips   553   369   684   427   \n",
       "3      image00000004.jpg   1280     720  Lips   555   351   681   408   \n",
       "4      image00000005.jpg   1280     720  Lips   555   351   680   407   \n",
       "...                  ...    ...     ...   ...   ...   ...   ...   ...   \n",
       "28589  image00028590.jpg   1280     720  Lips   657   347   817   450   \n",
       "28590  image00028591.jpg   1280     720  Lips   713   325   884   388   \n",
       "28591  image00028592.jpg   1280     720  Lips   659   401   808   488   \n",
       "28592  image00028593.jpg   1280     720  Lips   689   334   839   431   \n",
       "28593  image00028594.jpg   1280     720  Lips   657   381   817   476   \n",
       "\n",
       "                   mask  \n",
       "0      mask00000001.png  \n",
       "1      mask00000002.png  \n",
       "2      mask00000003.png  \n",
       "3      mask00000004.png  \n",
       "4      mask00000005.png  \n",
       "...                 ...  \n",
       "28589  mask00028590.png  \n",
       "28590  mask00028591.png  \n",
       "28591  mask00028592.png  \n",
       "28592  mask00028593.png  \n",
       "28593  mask00028594.png  \n",
       "\n",
       "[28594 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data\\list.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([720, 675], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['height'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filepaths\n",
    "\n",
    "img_fp = 'data/720p'\n",
    "masks_fp = 'data/mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28594, 28540)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = glob(masks_fp+'/*')\n",
    "images = glob(img_fp+'/*')\n",
    "\n",
    "# Для изображений в датасете есть не все маски\n",
    "len(images), len(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add relative path to images and masks\n",
    "df['filename'] = img_fp + '/' + df['filename'].astype(str)\n",
    "df['mask'] = masks_fp + '/' + df['mask'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/720p/image00000001.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>661</td>\n",
       "      <td>394</td>\n",
       "      <td>776</td>\n",
       "      <td>444</td>\n",
       "      <td>data/mask/mask00000001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/720p/image00000002.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>557</td>\n",
       "      <td>336</td>\n",
       "      <td>682</td>\n",
       "      <td>392</td>\n",
       "      <td>data/mask/mask00000002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/720p/image00000003.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>553</td>\n",
       "      <td>369</td>\n",
       "      <td>684</td>\n",
       "      <td>427</td>\n",
       "      <td>data/mask/mask00000003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/720p/image00000004.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>555</td>\n",
       "      <td>351</td>\n",
       "      <td>681</td>\n",
       "      <td>408</td>\n",
       "      <td>data/mask/mask00000004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/720p/image00000005.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>Lips</td>\n",
       "      <td>555</td>\n",
       "      <td>351</td>\n",
       "      <td>680</td>\n",
       "      <td>407</td>\n",
       "      <td>data/mask/mask00000005.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  width  height class  xmin  ymin  xmax  ymax  \\\n",
       "0  data/720p/image00000001.jpg   1280     720  Lips   661   394   776   444   \n",
       "1  data/720p/image00000002.jpg   1280     720  Lips   557   336   682   392   \n",
       "2  data/720p/image00000003.jpg   1280     720  Lips   553   369   684   427   \n",
       "3  data/720p/image00000004.jpg   1280     720  Lips   555   351   681   408   \n",
       "4  data/720p/image00000005.jpg   1280     720  Lips   555   351   680   407   \n",
       "\n",
       "                         mask  \n",
       "0  data/mask/mask00000001.png  \n",
       "1  data/mask/mask00000002.png  \n",
       "2  data/mask/mask00000003.png  \n",
       "3  data/mask/mask00000004.png  \n",
       "4  data/mask/mask00000005.png  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search done, rows to remove: 54\n"
     ]
    }
   ],
   "source": [
    "# delete rows if real images not found for it\n",
    "idx_to_drop = []\n",
    "\n",
    "for idx in df.index:\n",
    "    cur_row = df.iloc[idx]\n",
    "    if not os.path.exists(cur_row['filename']) or not os.path.exists(cur_row['mask']):\n",
    "        # list_df = list_df.drop(idx, axis=0)\n",
    "        idx_to_drop.append(idx)\n",
    "        \n",
    "print(f\"Search done, rows to remove: {len(idx_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(idx_to_drop, axis=0)\n",
    "df = df[['filename', 'mask']]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28540, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/720p/image00000001.jpg</td>\n",
       "      <td>data/mask/mask00000001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/720p/image00000002.jpg</td>\n",
       "      <td>data/mask/mask00000002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/720p/image00000003.jpg</td>\n",
       "      <td>data/mask/mask00000003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/720p/image00000004.jpg</td>\n",
       "      <td>data/mask/mask00000004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/720p/image00000005.jpg</td>\n",
       "      <td>data/mask/mask00000005.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename                        mask\n",
       "0  data/720p/image00000001.jpg  data/mask/mask00000001.png\n",
       "1  data/720p/image00000002.jpg  data/mask/mask00000002.png\n",
       "2  data/720p/image00000003.jpg  data/mask/mask00000003.png\n",
       "3  data/720p/image00000004.jpg  data/mask/mask00000004.png\n",
       "4  data/720p/image00000005.jpg  data/mask/mask00000005.png"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetFromImages(Dataset):\n",
    "    def __init__(self, data_info):\n",
    "        # Подаем наш подготовленный датафрейм\n",
    "        self.data_info = data_info\n",
    "        \n",
    "        # Разделяем датафрейм на rgb картинки \n",
    "        self.image_arr = self.data_info.iloc[:,0]\n",
    "        # и на сегментированные картинки\n",
    "        self.label_arr = self.data_info.iloc[:,1]\n",
    "        \n",
    "        # Количество пар картинка-сегментация\n",
    "        self.data_len = len(self.data_info.index)\n",
    "    def __getitem__(self, index):\n",
    "        # Читаем картинку и сразу же представляем ее в виде numpy-массива \n",
    "        # размера XxY float-значений\n",
    "        img = np.asarray(Image.open(self.image_arr[index])).astype('float')\n",
    "        # Нормализуем изображение в значениях [0,1]\n",
    "        img = torch.as_tensor(img)/255    \n",
    "        # 1) unsqueeze - меняет размерность img c (x, y, 3) -> (1, x, y, 3),\n",
    "        # т.е. оборачивает картинку в батч размером в одну картинку\n",
    "        # 2) permute - меняет местами измерения , т.е. (1, x, y, 3) -> (1, 3, x, y)\n",
    "        img = img.unsqueeze(0).permute(0,3,1,2)\n",
    "        # Мы используем функцию интерполяции для того,\n",
    "        # чтобы поменять рамерность картинки с XxY на 256х256\n",
    "        img = F.interpolate(input=img, size=256, align_corners=False, mode='bicubic')\n",
    "        \n",
    "        # итаем сегментированную картинку и сразу же представляем ее в виде numpy-массива \n",
    "        # размера XY float-значений\n",
    "        lab = np.asarray(plt.imread(self.label_arr[index]))[:,:,0]*255\n",
    "        \n",
    "        # Упаковываем ее в pytorch-тензор и оборачиваем ее в батч из одной каринки,\n",
    "        # но при этом заполняем 2 каналов масками нужных классов\n",
    "        # Т.е. там, где губы - все пиксели 1 \n",
    "        # если не принадлежат классу, и 0 если принадлежат \n",
    "        x_out = torch.as_tensor(np.where(lab == 0, 255, 0)).unsqueeze(0)\n",
    "        for i in range(1, 2):\n",
    "            mask = np.asarray(plt.imread(self.label_arr[index]))[:,:,0]*255\n",
    "            mask = np.where(mask == i, 255, 0)\n",
    "            x = torch.as_tensor(mask).unsqueeze(0)\n",
    "            x_out =  torch.cat((x_out,x),dim=0)    \n",
    "        x_out = x_out.float()\n",
    "        \n",
    "        lab = x_out.unsqueeze(0)\n",
    "        # делаем ресайз картинки на 256х256\n",
    "        lab = F.interpolate(input=lab, size=256, mode='nearest')\n",
    "        \n",
    "        \n",
    "        \n",
    "        return (img.float(), lab.float())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray(Image.open(df.iloc[:,0][0])).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset in frac 0.7 to 0.3\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size=0.3)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оборачиваем каждую выборку в наш кастомный датасет\n",
    "train_data = CustomDatasetFromImages(X_train)\n",
    "test_data = CustomDatasetFromImages(X_test)\n",
    "\n",
    "train_data_loader = DataLoader(train_data, batch_size=128,shuffle=True)\n",
    "test_data_loader = DataLoader(train_data, batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели\n",
    "segmodel = smp.Unet()\n",
    "segmodel = smp.Unet('resnet34', classes=2, activation='softmax').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(segmodel.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        smooth =1\n",
    "        num = targets.size(0)\n",
    "        probs = logits\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score =(2. * intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        #print(score.sum())\n",
    "        score =1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = SoftDiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\segmentation_models_pytorch\\base\\modules.py:102: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index : 0 | loss : 0.4686161279678345\n",
      "batch index : 1 | loss : 0.3071622848510742\n",
      "batch index : 2 | loss : 0.36870336532592773\n",
      "batch index : 3 | loss : 0.2993308901786804\n",
      "batch index : 4 | loss : 0.19795870780944824\n",
      "batch index : 5 | loss : 0.07155531644821167\n",
      "batch index : 6 | loss : 0.04137539863586426\n",
      "batch index : 7 | loss : 0.11171424388885498\n",
      "batch index : 8 | loss : 0.2219374179840088\n",
      "batch index : 9 | loss : -0.052559852600097656\n",
      "batch index : 10 | loss : 0.06206715106964111\n",
      "batch index : 11 | loss : 0.04565197229385376\n",
      "batch index : 12 | loss : -0.20890676975250244\n",
      "batch index : 13 | loss : -0.23346519470214844\n",
      "batch index : 14 | loss : -0.3938620090484619\n",
      "batch index : 15 | loss : -0.36261510848999023\n",
      "batch index : 16 | loss : -0.4848790168762207\n",
      "batch index : 17 | loss : -0.47525954246520996\n",
      "batch index : 18 | loss : -0.32287323474884033\n",
      "batch index : 19 | loss : -0.44463610649108887\n",
      "batch index : 20 | loss : -0.4322526454925537\n",
      "batch index : 21 | loss : -0.558600902557373\n",
      "batch index : 22 | loss : -0.39820170402526855\n",
      "batch index : 23 | loss : -0.5839071273803711\n",
      "batch index : 24 | loss : -0.5146467685699463\n",
      "batch index : 25 | loss : -0.6543694734573364\n",
      "batch index : 26 | loss : -0.6135333776473999\n",
      "batch index : 27 | loss : -0.6458926200866699\n",
      "batch index : 28 | loss : -0.6212702989578247\n",
      "batch index : 29 | loss : -0.6713937520980835\n",
      "batch index : 30 | loss : 0.03664880990982056\n",
      "batch index : 31 | loss : -0.6494004726409912\n",
      "batch index : 32 | loss : -0.6419157981872559\n",
      "batch index : 33 | loss : -0.7747735977172852\n",
      "batch index : 34 | loss : -0.666818380355835\n",
      "batch index : 35 | loss : -0.7197582721710205\n",
      "batch index : 36 | loss : -0.6981450319290161\n",
      "batch index : 37 | loss : -0.7867186069488525\n",
      "batch index : 38 | loss : -0.7696802616119385\n",
      "batch index : 39 | loss : -0.8095991611480713\n",
      "batch index : 40 | loss : 0.02303558588027954\n",
      "batch index : 41 | loss : 0.02188187837600708\n",
      "batch index : 42 | loss : -0.8146176338195801\n",
      "batch index : 43 | loss : -0.0033789873123168945\n",
      "batch index : 44 | loss : -0.7985341548919678\n",
      "batch index : 45 | loss : -0.780913233757019\n",
      "batch index : 46 | loss : -0.6059062480926514\n",
      "batch index : 47 | loss : 0.04423242807388306\n",
      "batch index : 48 | loss : -0.6941578388214111\n",
      "batch index : 49 | loss : -0.7291133403778076\n",
      "batch index : 50 | loss : 0.03637212514877319\n",
      "batch index : 51 | loss : -0.08485114574432373\n",
      "batch index : 52 | loss : 0.03819328546524048\n",
      "batch index : 53 | loss : -0.21437466144561768\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    epoch_loss = []\n",
    "    time1 = time.time()\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = segmodel(inputs[0])\n",
    "        loss = criterion(outputs,labels[0,0,:,:,:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        epoch_loss.append(loss.item())\n",
    "        print(f'batch index : {i} | loss : {loss.item()}')\n",
    "\n",
    "    print(f'Epoch {epoch+1}, loss: ',np.mean(epoch_loss))\n",
    "    time2 = time.time()\n",
    "    print(f'Spend time for 1 epoch: {time2-time1} sec')\n",
    "    \n",
    "    epoch_losses.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orig(image):\n",
    "    #image = images[0,:,:,:]\n",
    "    image = image.permute(1, 2, 0)\n",
    "    image = image.numpy()\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2881\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2882\u001b[1;33m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2883\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-efd6cd3ab714>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-714ba9900c9f>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Читаем картинку и сразу же представляем ее в виде numpy-массива\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# размера XxY float-значений\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;31m# Нормализуем изображение в значениях [0,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2882\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2883\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2884\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2885\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(test_data_loader):\n",
    "    images, labels = data\n",
    "    outputs = segmodel(images[0])\n",
    "    f, axarr = plt.subplots(1,3)\n",
    "\n",
    "    axarr[0].imshow(outputs.detach().cpu().numpy()[0,0,:,:])\n",
    "    axarr[0].set_title('Guessed labels')\n",
    "    \n",
    "    axarr[1].imshow(labels[0].detach().cpu().numpy()[0,0,:,:])\n",
    "    axarr[1].set_title('Ground truth labels')\n",
    "    \n",
    "    original = get_orig(images[0][0,:,:,:])\n",
    "    axarr[2].imshow(original)\n",
    "    axarr[2].set_title('Original Images')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.gcf().show()\n",
    "    if i>3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
